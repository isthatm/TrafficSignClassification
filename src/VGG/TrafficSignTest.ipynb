{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVWiOsBJkLyn"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kydzecyXpox7"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import sys\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5adTFD1oifs"
   },
   "source": [
    "##**Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "T-ZWONxLra2t",
    "outputId": "d43ce840-2e60-4480-80c9-936c3ec9e234"
   },
   "outputs": [],
   "source": [
    "label_name_mapping = {\n",
    "    0: \"3-junction\",\n",
    "    1: \"One-way road\",\n",
    "    2: \"Side to obe followed\",\n",
    "    3: \"Cross road\",\n",
    "    4: \"Intersection with Uncontrolled Road\",\n",
    "    5: \"Dangerous turn\",\n",
    "    6: \"No Left turn\",\n",
    "    7: \"Bus stop\",\n",
    "    8: \"Roundabout\",\n",
    "    9: \"No parking and stopping\",\n",
    "    10: \"U-turn\",\n",
    "    11: \"Lane-allocation\",\n",
    "    12: \"No left turn for motorcycles\",\n",
    "    13: \"Slow Down\",\n",
    "    14: \"No Trucks Allowed\",\n",
    "    15: \"Narrow Road on the Right\",\n",
    "    16: \"No Passenger Cars and Trucks\",\n",
    "    17: \"Height Limit\",\n",
    "    18: \"No U-Turn\",\n",
    "    19: \"No U-Turn and No Right Turn\",\n",
    "    20: \"No Cars Allowed\",\n",
    "    21: \"Narrow Road on the Left\",\n",
    "    22: \"Uneven Road\",\n",
    "    23: \"No Two or Three-wheeled Vehicles\",\n",
    "    24: \"Customs Checkpoint\",\n",
    "    25: \"Motorcycles Only\",\n",
    "    26: \"Obstacle on the Road\",\n",
    "    27: \"Children Presence\",\n",
    "    28: \"Trucks and Containers\",\n",
    "    29: \"No Motorcycles Allowed\",\n",
    "    30: \"Trucks Only\",\n",
    "    31: \"Road with Surveillance Camera\",\n",
    "    32: \"No Right Turn\",\n",
    "    33: \"Series of Dangerous Turns\",\n",
    "    34: \"No Containers Allowed\",\n",
    "    35: \"No Left or Right Turn\",\n",
    "    36: \"No Straight and Right Turn\",\n",
    "    37: \"Intersection with T-Junction\",\n",
    "    38: \"Speed limit (50km/h)\",\n",
    "    39: \"Speed limit (60km/h)\",\n",
    "    40: \"Speed limit (80km/h)\",\n",
    "    41: \"Speed limit (40km/h)\",\n",
    "    42: \"Left Turn\",\n",
    "    43: \"Low Clearance\",\n",
    "    44: \"Other Danger\",\n",
    "    45: \"Go Straight\",\n",
    "    46: \"No Parking\",\n",
    "    47: \"No Left or U-turn\",\n",
    "    48: \"No U-Turn for Cars\",\n",
    "    49: \"Level Crossing with Barriers\"\n",
    "}\n",
    "\n",
    "def display_batch(images, labels_tensor, confidence_tensor):\n",
    "\n",
    "    for i, (top_preds, top_lbls) in enumerate(zip(confidence_tensor, labels_tensor)):  # Iterate over each image in the batch\n",
    "      fig = plt.figure(figsize=(10, 5))\n",
    "      conf_list = top_preds.tolist()\n",
    "      lbl_list  = top_lbls.tolist()\n",
    "\n",
    "      # Create a grid layout with 1 row and 2 columns\n",
    "      gs = plt.GridSpec(1, 2, width_ratios=[1, 1])  # Left 1: image, right 2: bar chart\n",
    "\n",
    "       # Left: Show the image\n",
    "      ax1 = fig.add_subplot(gs[0])\n",
    "      ax1.imshow(images[i].permute(1, 2, 0))  # Show the image for the current batch item\n",
    "      ax1.axis('off')  # Turn off the axis for the image\n",
    "\n",
    "      # Right: Create the horizontal bar chart for the current image's top 5 predictions\n",
    "      ax2 = fig.add_subplot(gs[1])\n",
    "\n",
    "      # Convert label indices to strings (or use a custom mapping if you have label names)\n",
    "      labels_str = [f\"{label_name_mapping[lbl]}\" for lbl in lbl_list]\n",
    "\n",
    "      # Plot the horizontal bar chart\n",
    "      bars = ax2.barh(labels_str, conf_list, color='skyblue')\n",
    "\n",
    "      # Add confidence values at the end of each bar\n",
    "      for bar, confidence in zip(bars, conf_list):\n",
    "        ax2.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2, f'{confidence:.2f}', va='center')\n",
    "\n",
    "      plt.xlabel('Confidence')\n",
    "      plt.xlim(0, 1)  # Assuming confidence is in the range 0 to 1, adjust if necessary\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "\n",
    "def pickle_data(file, writeColumns=None):\n",
    "    \"\"\"\n",
    "    Read/Write pickle training/testing data, models to avoid\n",
    "    loading data again (time consuming)\n",
    "\n",
    "    :param file: path to pickle file\n",
    "    :param writeColumns (torch.Tensor or np.ndarray): variables to be saved to pickle file\n",
    "\n",
    "    :returns :\n",
    "    If writeColumns = None -> tuple(torch.Tensor)\n",
    "    tuple()\n",
    "    \"\"\"\n",
    "    if writeColumns is None:\n",
    "        with open(file, mode=\"rb\") as f:\n",
    "            dataset = pickle.load(f)\n",
    "            return tuple( # Convert the pickled data into tensor if it is of any other types\n",
    "                map(lambda col: torch.tensor(dataset[col])\n",
    "                    if not type(dataset[col]) == torch.Tensor else dataset[col],\n",
    "                    ['images', 'labels'])\n",
    "                )\n",
    "                # lambda(col) where columns are the inputs\n",
    "    else:\n",
    "        with open(file, mode=\"wb\") as f:\n",
    "            dataset = pickle.dump({\"images\": writeColumns[0], \"labels\": writeColumns[1]}, f)\n",
    "            print(\"Data is saved in\", file)\n",
    "\n",
    "    def preprocess_batch(batch_tensor):\n",
    "      preprocessed_image = []\n",
    "      idx = 0\n",
    "      for img_tensor in batch_tensor:\n",
    "         # Convert tensor to numpy array\n",
    "        #print(\"{}: {}\".format(idx, img_tensor.size()))\n",
    "        img_np = img_tensor.permute(1, 2, 0).numpy()  # [C, H, W] -> [H, W, C]\n",
    "\n",
    "         # Convert from [0, 1] or [0, 255] to [0, 255] and ensure uint8 type\n",
    "        if img_np.max() <= 1.0:\n",
    "            img_np = (img_np * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img_np = img_np.astype(np.uint8)\n",
    "\n",
    "        img_res = preprocess(img_np)\n",
    "        img_tensor = torch.from_numpy(img_res).unsqueeze(0)\n",
    "        preprocessed_image.append(img_tensor)\n",
    "        idx += 1\n",
    "\n",
    "      preprocessed_tensor = torch.stack(preprocessed_image)\n",
    "      return preprocessed_tensor\n",
    "\n",
    "def preprocess(image):\n",
    "    if image.shape[2] > 1:\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "      # Noise reduction\n",
    "      image = cv2.GaussianBlur(image, (3, 3), 1,5)\n",
    "      # Histogram equalization\n",
    "      image = cv2.equalizeHist(image)\n",
    "      # Image eroding\n",
    "      image = cv2.erode(image, (3, 3))\n",
    "      # Resize image\n",
    "      image = cv2.resize(image, (32, 32))\n",
    "    return image\n",
    "\n",
    "class CustomDataset(TensorDataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Vietnam\n",
    "torch.manual_seed(41)\n",
    "vietnam_imgs, vietnam_labels = pickle_data(file = '/content/drive/MyDrive/TrafficSignData/Vietnam/gray_processed_dataset') # Update your path or you can use the pickled data that I uploaded at /Data\n",
    "portion    = 0.8\n",
    "train_size = int(portion * len(vietnam_imgs))\n",
    "val_size   = len(vietnam_imgs) - train_size\n",
    "train_dataset, val_dataset = random_split(list(zip(vietnam_imgs, vietnam_labels)), [train_size, val_size])\n",
    "\n",
    "# Investigate the dataset\n",
    "batch_size     = 32\n",
    "images_per_row = 8\n",
    "num_rows       = batch_size // images_per_row + (1 if batch_size % images_per_row > 0 else 0)\n",
    "sample_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, images_per_row, figsize=(12, 4 * num_rows), gridspec_kw={'hspace': 0.5, 'wspace': 0.5})\n",
    "axes = axes.flatten()\n",
    "for _, (input, target) in enumerate(sample_loader):\n",
    "  for img_idx in range(batch_size):\n",
    "    axes[img_idx].imshow(input[img_idx].permute(1, 2, 0))  # Display the image\n",
    "    axes[img_idx].axis('off')  # Turn off the axis\n",
    "  break\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.show()\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI0dFA-Zwkiy"
   },
   "source": [
    "## **Network**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGYuOWI_wrjg"
   },
   "outputs": [],
   "source": [
    "# Ensure that the input tensor size is [batch_size, channel, width, heigh]\n",
    "# Ensure that the labels are int64\n",
    "# Ensure that the ouput of the classfier matches the number of classes\n",
    "\n",
    "supportedArch = [\n",
    "    'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
    "    'vgg19_bn', 'vgg19',\n",
    "]\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    '''\n",
    "    VGG model\n",
    "    '''\n",
    "    def __init__(self, vgg_blocks):\n",
    "        super(VGG, self).__init__()\n",
    "        self.layers = nn.ModuleList(vgg_blocks)\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1408, 1024), \n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 50),\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "      output   = []\n",
    "      tmpInput = x\n",
    "      # 1. VGG blocks\n",
    "      for layerIdx, layer in enumerate(self.layers):\n",
    "        current_output = layer(tmpInput)\n",
    "        output.append(current_output)\n",
    "        tmpInput = current_output\n",
    "\n",
    "      # 2. Multiscale Convolutional Network\n",
    "      output_m1 = torch.cat((self.maxPool (output[1]), output[2]), 1)\n",
    "      output_m2 = torch.cat((self.maxPool (output_m1), output[3]), 1)\n",
    "      output_m3 = torch.cat((self.maxPool (output_m2), output[4]), 1)\n",
    "\n",
    "      ouput_pre_classification = output_m3.view(output_m3.size(0), -1)\n",
    "      final_ouput = self.classifier(ouput_pre_classification)\n",
    "      return final_ouput\n",
    "\n",
    "    def vgg11():\n",
    "        \"\"\"VGG 11-layer model (configuration \"A\")\"\"\"\n",
    "        return VGG(make_layers(cfg['A']))\n",
    "\n",
    "\n",
    "    def vgg11_bn():\n",
    "        \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\"\"\"\n",
    "        return VGG(make_layers(cfg['A'], batch_norm=True))\n",
    "\n",
    "\n",
    "    def vgg13():\n",
    "        \"\"\"VGG 13-layer model (configuration \"B\")\"\"\"\n",
    "        return VGG(make_layers(cfg['B']))\n",
    "\n",
    "\n",
    "    def vgg13_bn():\n",
    "        \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n",
    "        return VGG(make_layers(cfg['B'], batch_norm=True))\n",
    "\n",
    "\n",
    "    def vgg16():\n",
    "        \"\"\"VGG 16-layer model (configuration \"D\")\"\"\"\n",
    "        return VGG(make_layers(cfg['D']))\n",
    "\n",
    "\n",
    "    def vgg16_bn():\n",
    "        \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\"\"\"\n",
    "        return VGG(make_layers(cfg['D'], batch_norm=True))\n",
    "\n",
    "\n",
    "    def vgg19():\n",
    "        \"\"\"VGG 19-layer model (configuration \"E\")\"\"\"\n",
    "        return VGG(make_layers(cfg['E']))\n",
    "\n",
    "\n",
    "    def vgg19_bn():\n",
    "        \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\"\"\"\n",
    "        return VGG(make_layers(cfg['E'], batch_norm=True))\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    vgg_blocks = []\n",
    "    in_channels = 1\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            vgg_sequential = nn.Sequential(*layers)\n",
    "            vgg_blocks.append(vgg_sequential)\n",
    "            layers = [] # empty the current block\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return vgg_blocks\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M',\n",
    "          512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "model_names = sorted(name for name in supportedArch\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "                     and name.startswith(\"vgg\")\n",
    "                    )\n",
    "\n",
    "best_prec1     = 0\n",
    "ARCH           = \"vgg16_bn\"\n",
    "WORKERS        = 4\n",
    "EPOCHS         = 100\n",
    "START_EPOCH    = 0\n",
    "BATCH_SIZE     = 32\n",
    "LEARNING_RATE  = 0.05\n",
    "MOMENTUM       = 0.9\n",
    "WEIGHT_DECAY   = 5E-4\n",
    "PRINT_FREQ     = 20\n",
    "RESUME         = \"/content/drive/MyDrive/TrafficSignData/Vietnam/24.10.07_Take1/checkpoint_96.tar\" # Path to model file (set as None to train)\n",
    "EVALUATE       = True # Train: Evaluate = False; Test: Evaluate = True\n",
    "HALF_PRECISION = False\n",
    "CPU            = False\n",
    "SAVE_DIR       = \"save_temp\"\n",
    "\n",
    "def main():\n",
    "    global best_prec1, START_EPOCH\n",
    "    print (VGG.__dict__)\n",
    "\n",
    "    # Check the save_dir exists or not\n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)\n",
    "\n",
    "    model_method = getattr(VGG, ARCH)\n",
    "    model = model_method()\n",
    "\n",
    "    if CPU:\n",
    "        model.cpu()\n",
    "    else:\n",
    "        model.cuda()\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if RESUME:\n",
    "        if os.path.isfile(RESUME):\n",
    "            print(\"=> loading checkpoint '{}'\".format(RESUME))\n",
    "            if not CPU:\n",
    "              checkpoint = torch.load(RESUME)\n",
    "            else:\n",
    "              checkpoint = torch.load(RESUME, map_location=torch.device('cpu'))\n",
    "            START_EPOCH = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(EVALUATE, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(RESUME))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # define loss function (criterion) and pptimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if CPU:\n",
    "        criterion = criterion.cpu()\n",
    "    else:\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    if HALF_PRECISION:\n",
    "        model.half()\n",
    "        criterion.half()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), LEARNING_RATE,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    if EVALUATE:\n",
    "        validate(val_loader, model, criterion)\n",
    "        return\n",
    "\n",
    "    for epoch in range(START_EPOCH, EPOCHS):\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "        }, is_best, filename=os.path.join(SAVE_DIR, 'checkpoint_{}.tar'.format(epoch)))\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "        Run one train epoch\n",
    "    \"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    data_time  = AverageMeter()\n",
    "    losses     = AverageMeter()\n",
    "    top1       = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        target = target.type(torch.int64)\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if CPU == False:\n",
    "            input = input.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "        if HALF_PRECISION:\n",
    "            input = input.half()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Run evaluation\n",
    "    \"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses     = AverageMeter()\n",
    "    top1       = AverageMeter()\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.type(torch.int64)\n",
    "        if CPU == False:\n",
    "            input = input.cuda(non_blocking = True)\n",
    "            target = target.cuda(non_blocking = True)\n",
    "\n",
    "        if HALF_PRECISION:\n",
    "            input = input.half()\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        output = output.float()\n",
    "\n",
    "        # Normalizing output 24.10.07\n",
    "        normalized_output = nn.functional.softmax(output, dim=1)\n",
    "\n",
    "        loss = loss.float()\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # if (i == 0):\n",
    "        #   maxk = max((5,))\n",
    "        #   batch_size = target.size(0)\n",
    "        #   conf, output_lbl = normalized_output.topk(maxk, 1, True, True)\n",
    "        #   output_lbl = output_lbl\n",
    "        #   conf       = conf\n",
    "        #   display_batch(input, output_lbl, conf)\n",
    "          #   break;\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                      i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                      top1=top1))\n",
    "\n",
    "    print(' * Prec@1 {top1.avg:.3f}'\n",
    "          .format(top1=top1))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    \"\"\"\n",
    "    Save the training model\n",
    "    \"\"\"\n",
    "    torch.save(state, filename)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 2 every 30 epochs\"\"\"\n",
    "    lr = LEARNING_RATE * (0.5 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
